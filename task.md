### Домашнее задание
Подготовка и установка на расписание DAG выгрузки данных из источников  
Цель:  
В данном ДЗ мы настроим автоматический data pipeline, который будет получать данные из публичного API и складывать их в БД для дальнейшего анализа.

Конечный продукт: 
1. работающий облачный инстанс Apache Airflow
2. data pipeline, содержащий в себе несколько task-ов и "крутящийся" по расписанию Airflow
3. работающий облачный инстанс СУБД, куда Airflow заливает данные, получаемые из внешнего API
4. данные в СУБД

Часть из операций мы разбирали на занятии. При необходимости - можно пересмотреть запись.
1. Создаем Виртуальную машину с Apache Airflow 2.0 в YandexCloud
2. Создаем "managed instance" PostgreSQL/ClickHouse/MySQL - по выбору в YandexCloud. Создаем БД "analytics".
3. Добавляем наш psql в Connections через UI Airflow.
4. Выбираем один из 2-х API, с которым будем работать:
   - Положение Международной Космической Станции на текущий момент времени (timestamp-latitude-longitude). Source: http://api.open-notify.org/iss-now.json
   - Курс BTC: https://docs.coincap.io/#2a87f3d4-f61f-42d3-97e0-3a9afa41c73b  
     Тут нас интересует следующий endpoint: "api.coincap.io/v2/rates/bitcoin"
5. Создаем схему данных (таблицу в бд analytics) с названиями и типами полей, релевантными тому, что будем забирать из API.
6. Описываем DAG (программируем на Python) для получения данных с периодичностью 30 min. Сам оператор для обращения к API можно выбрать любой. Для простоты рекомендуется слать GET-запросы через python-библиотеку requests (PythonOperator), либо через bash (BashOperator) с помощью curl.  
Концептуальная схема Dag-a: отправить запрос в API->распарсить пришедший результат->положить данные в БД (сделать insert в таблицу)
7. Кладем .py файл с DAG-ом в нужную директорию виртуалки с airflow.
8. Запускаем DAG тумблером в UI Airflow
9. Отлаживаем DAG до работоспособного состояния.  
В интерфейсе Airflow (облачный инстанс) есть информация о наборе успешно завершившихся Dag runs (темно-зеленые кружки) + в БД есть данные за >5 периодов времени.  
В качестве проверки мы зайдем в вам airflow webserver и отправим sql-запрос в таблицу с данными.
10. Проверяем, что данные появились в БД.
11. Поздравляю, Вы завершили ДЗ!

Критерии оценки:  
"Принято" - задание выполнено полностью "Возвращено на доработку" - задание не выполнено полностью  
Рекомендуем сдать до: 06.10.2021
